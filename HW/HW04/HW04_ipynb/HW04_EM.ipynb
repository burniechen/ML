{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "def GetImageData(f):\n",
    "    # magic number\n",
    "    f.read(4) \n",
    "    \n",
    "    # number of images\n",
    "    num = f.read(4)\n",
    "    num = int.from_bytes(num, byteorder='big') #60000\n",
    "\n",
    "    row = f.read(4)\n",
    "    row = int.from_bytes(row, byteorder='big') #28\n",
    "\n",
    "    column = f.read(4)\n",
    "    column = int.from_bytes(column, byteorder='big') #28\n",
    "\n",
    "    buf = f.read(row * column * num)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = data.reshape(num, row * column)\n",
    "    \n",
    "    return [data, num, row, column]\n",
    "\n",
    "def GetLabelData(f):\n",
    "    # magic number\n",
    "    f.read(4) \n",
    "\n",
    "    # number of items\n",
    "    num = f.read(4)\n",
    "    num = int.from_bytes(num, byteorder='big') #10000\n",
    "\n",
    "    buf = f.read(num)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    data = data.reshape(num)\n",
    "    \n",
    "    return [data, num]\n",
    "\n",
    "def GetIndexOfEachLabel(label_data):\n",
    "    index = 0\n",
    "    index_m = []\n",
    "    for num in range(10):\n",
    "        index_m.append([])\n",
    "        for label in label_data:\n",
    "            if label == num:\n",
    "                index_m[num].append(index)\n",
    "            index +=1\n",
    "        index = 0\n",
    "        \n",
    "    return index_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "train_image = 'train-images-idx3-ubyte.gz'\n",
    "train_label = 'train-labels-idx1-ubyte.gz'\n",
    "\n",
    "test_image = 't10k-images-idx3-ubyte.gz'\n",
    "test_label = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# Train\n",
    "f = gzip.open(train_image,'rb')\n",
    "data = GetImageData(f)\n",
    "train_image_data, train_image_num, row, column = data\n",
    "\n",
    "f = gzip.open(train_label,'rb')\n",
    "data = GetLabelData(f)\n",
    "train_label_data, train_label_num = data\n",
    "\n",
    "# Test\n",
    "f = gzip.open(test_image,'rb')\n",
    "data = GetImageData(f)\n",
    "test_image_data, test_image_num, row, column = data\n",
    "\n",
    "f = gzip.open(test_label,'rb')\n",
    "data = GetLabelData(f)\n",
    "test_label_data, test_label_num = data\n",
    "\n",
    "train_grey_data = np.where(train_image_data < 128, 0, 1)\n",
    "\n",
    "c = 60000\n",
    "\n",
    "w = np.zeros((c, 10)) # w[60000][10]\n",
    "lam = np.zeros((10, )) # lam[10]\n",
    "prob = np.zeros((row*column, 10)) # prob[784][10]\n",
    "\n",
    "train_index = GetIndexOfEachLabel(train_label_data)\n",
    "\n",
    "for i in range(len(train_index)):\n",
    "    lam[i] = len(train_index[i])\n",
    "lam = lam/train_image_num\n",
    "\n",
    "peudoP = 0.5\n",
    "prob += peudoP\n",
    "\n",
    "@jit\n",
    "def EM(lam, w, prob, c, train_grey_data):\n",
    "    for n in range(c):\n",
    "        for label in range(10):\n",
    "            w[n][label] = lam[label]\n",
    "            \n",
    "    for t in range(15):\n",
    "        # E-step\n",
    "        for n in range(c):\n",
    "            totalP = 0\n",
    "            for pixel in range(row*column):\n",
    "                for label in range(10):\n",
    "                    w[n][label] *= (prob[pixel][label] ** train_grey_data[n][pixel]) * ((1 - prob[pixel][label]) ** (1 - train_grey_data[n][pixel]))\n",
    "\n",
    "                if pixel % 10 == 0:\n",
    "                    w[n] /= w[n].sum()\n",
    "\n",
    "            w[n] /= w[n].sum()\n",
    "\n",
    "        # M-step\n",
    "        lamMLE = np.zeros((10, ))\n",
    "\n",
    "        for label in range(10):\n",
    "            totalW = w[:, label].sum()\n",
    "            lamMLE[label] = totalW/c\n",
    "\n",
    "        lamMLE = lamMLE/lamMLE.sum()    \n",
    "\n",
    "        for label in range(10):\n",
    "            for pixel in range(784):\n",
    "                P = 0\n",
    "                totalP = 0\n",
    "                for i in range(c):\n",
    "                    P += w[i][label]*train_grey_data[i][pixel]\n",
    "                    totalP += w[i][label]\n",
    "                prob[pixel][label] = P / totalP\n",
    "\n",
    "        lam = lamMLE\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_prob = EM(lam, w, prob, c, train_grey_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000011111000000000\n",
      "0000000000000111111000000000\n",
      "0000000000000111110000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000111100000000000000\n",
      "0000000000111101111000000000\n",
      "0000000000111011111100000000\n",
      "0000000001110001111100000000\n",
      "0000000001110000011100000000\n",
      "0000000001100000011100000000\n",
      "0000000001100000111100000000\n",
      "0000000001110011111000000000\n",
      "0000000001111111110000000000\n",
      "0000000011111111100000000000\n",
      "0000000001111110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000011111000000000\n",
      "0000000000001111111110000000\n",
      "0000000000011111111110000000\n",
      "0000000000111111111111000000\n",
      "0000000001111110001111100000\n",
      "0000000011111000000111100000\n",
      "0000000011110000000011100000\n",
      "0000000111100000000011100000\n",
      "0000000111100000000011100000\n",
      "0000001111000000000011100000\n",
      "0000001111000000000011100000\n",
      "0000001110000000000111100000\n",
      "0000001110000000000111000000\n",
      "0000001110000000011111000000\n",
      "0000001111000000111110000000\n",
      "0000001111111111111100000000\n",
      "0000000111111111111000000000\n",
      "0000000011111111100000000000\n",
      "0000000000111110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000011111000000000000\n",
      "0000000000011000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000001100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000111100000000\n",
      "0000000000000011111100000000\n",
      "0000000011101111111000000000\n",
      "0000000111111111111010000000\n",
      "0000000111111111111110000000\n",
      "0000000111111111111111000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111100000000\n",
      "0000000000011110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000001111111100000\n",
      "0000000000000111111111100000\n",
      "0000000000001110001111000000\n",
      "0000000000011100001110000000\n",
      "0000000000111000001100000000\n",
      "0000000000111000011000000000\n",
      "0000000000111001111000000000\n",
      "0000000000111111110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000011111100000000000\n",
      "0000000000001111100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000111110000000000000\n",
      "0000000011111110000000000000\n",
      "0000000011111100000000000000\n",
      "0000000001110000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000001100000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000111111100000000\n",
      "0000000000011111111100000000\n",
      "0000000000111111111110000000\n",
      "0000000001111000011100000000\n",
      "0000000001110000011100000000\n",
      "0000000001100000111100000000\n",
      "0000000000000000111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000111111110000000000\n",
      "0000000001111111111000000000\n",
      "0000000011111111111000000000\n",
      "0000000001100000111000000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000111110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000111111111000000000\n",
      "0000000000011111111100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000001110000000\n",
      "0000000000000000000110000000\n",
      "0000000000000000000110000000\n",
      "0000000000000000001110000000\n",
      "0000000000000000011110000000\n",
      "0000000011111111111100000000\n",
      "0000000011111111111000000000\n",
      "0000000000111111100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111100000000000\n",
      "0000000000111111111000000000\n",
      "0000000001111001111000000000\n",
      "0000000011110000111000000000\n",
      "0000000011100000111000000000\n",
      "0000000011000000111000000000\n",
      "0000000001000000111000000000\n",
      "0000000001000001111000000000\n",
      "0000000000100001111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111111100000000\n",
      "0000000000011111111110000000\n",
      "0000000000111110011110000000\n",
      "0000000001111000001110000000\n",
      "0000000001110000001100000000\n",
      "0000000001110000001100000000\n",
      "0000000001110000011000000000\n",
      "0000000001111111111000000000\n",
      "0000000001111111110000000000\n",
      "0000000000111111111000000000\n",
      "0000000000011111111000000000\n",
      "0000000000011001111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000011110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000111111100000000000\n",
      "0000000000001110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000011110000000000000\n",
      "0000000001111111100000000000\n",
      "0000000011110001110000000000\n",
      "0000000011000000110000000000\n",
      "0000000010000000110000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000001111111000000000\n",
      "0000000000011111111000000000\n",
      "0000000000001111111100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "tmp_prob = np.reshape(tmp_prob, (28, 28, 10))\n",
    "\n",
    "for label in range(10):\n",
    "    print(\"\\n\\n\")\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if tmp_prob[i][j][label] >= 0.45:\n",
    "                print(1, end='')\n",
    "            else:\n",
    "                print(0, end='')\n",
    "#             print(tmp_prob[label][i][j], end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "13624\n",
      "1.0\n",
      "16362\n",
      "1.0\n",
      "3141\n",
      "1.0\n",
      "13693\n",
      "1.0\n",
      "24473\n",
      "1.0\n",
      "20458\n",
      "1.0\n",
      "8629\n",
      "1.0\n",
      "21528\n",
      "1.0\n",
      "6279\n",
      "1.0\n",
      "5865\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(w[:, i].max())\n",
    "    print(list(w[:, i]).count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def ReloadP(lam, w, prob, c, train_grey_data):\n",
    "    for n in range(c):\n",
    "        for label in range(10):\n",
    "            w[n][label] = lam[label]\n",
    "    for n in range(c):\n",
    "        totalP = 0\n",
    "        for pixel in range(row*column):\n",
    "            for label in range(10):\n",
    "                w[n][label] *= (prob[pixel][label] ** train_grey_data[n][pixel]) * ((1 - prob[pixel][label]) ** (1 - train_grey_data[n][pixel]))\n",
    "\n",
    "            if pixel % 10 == 0:\n",
    "                w[n] /= w[n].sum()\n",
    "\n",
    "        w[n] /= w[n].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReloadP(lam, w, prob, c, train_grey_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix 0 :\n",
      "                 Predict number 0   Predict not number 0\n",
      "Is number 0        879                        5044\n",
      "Is not number 0    6600                       47477\n",
      "Sensitivity (Successfully predict number 0) : 0.14840452473408747\n",
      "Specificity (Successfully predict not number 0) : 0.8779518094568856\n",
      "\n",
      "Confusion Matrix 1 :\n",
      "                 Predict number 1   Predict not number 1\n",
      "Is number 1        0                        6742\n",
      "Is not number 1    5026                       48232\n",
      "Sensitivity (Successfully predict number 1) : 0.0\n",
      "Specificity (Successfully predict not number 1) : 0.905629201246761\n",
      "\n",
      "Confusion Matrix 2 :\n",
      "                 Predict number 2   Predict not number 2\n",
      "Is number 2        4170                        1788\n",
      "Is not number 2    3808                       50234\n",
      "Sensitivity (Successfully predict number 2) : 0.6998992950654582\n",
      "Specificity (Successfully predict not number 2) : 0.92953628659191\n",
      "\n",
      "Confusion Matrix 3 :\n",
      "                 Predict number 3   Predict not number 3\n",
      "Is number 3        244                        5887\n",
      "Is not number 3    6319                       47550\n",
      "Sensitivity (Successfully predict number 3) : 0.03979774914369597\n",
      "Specificity (Successfully predict not number 3) : 0.882696912881249\n",
      "\n",
      "Confusion Matrix 4 :\n",
      "                 Predict number 4   Predict not number 4\n",
      "Is number 4        102                        5740\n",
      "Is not number 4    8435                       45723\n",
      "Sensitivity (Successfully predict number 4) : 0.017459774049982883\n",
      "Specificity (Successfully predict not number 4) : 0.8442520033974666\n",
      "\n",
      "Confusion Matrix 5 :\n",
      "                 Predict number 5   Predict not number 5\n",
      "Is number 5        35                        5386\n",
      "Is not number 5    6463                       48116\n",
      "Sensitivity (Successfully predict number 5) : 0.006456373362848183\n",
      "Specificity (Successfully predict not number 5) : 0.8815844922039612\n",
      "\n",
      "Confusion Matrix 6 :\n",
      "                 Predict number 6   Predict not number 6\n",
      "Is number 6        40                        5878\n",
      "Is not number 6    6728                       47354\n",
      "Sensitivity (Successfully predict number 6) : 0.006759040216289287\n",
      "Specificity (Successfully predict not number 6) : 0.8755963167042639\n",
      "\n",
      "Confusion Matrix 7 :\n",
      "                 Predict number 7   Predict not number 7\n",
      "Is number 7        2078                        4187\n",
      "Is not number 7    4273                       49462\n",
      "Sensitivity (Successfully predict number 7) : 0.331683958499601\n",
      "Specificity (Successfully predict not number 7) : 0.9204801339908811\n",
      "\n",
      "Confusion Matrix 8 :\n",
      "                 Predict number 8   Predict not number 8\n",
      "Is number 8        2223                        3628\n",
      "Is not number 8    3295                       50854\n",
      "Sensitivity (Successfully predict number 8) : 0.379935053836951\n",
      "Specificity (Successfully predict not number 8) : 0.9391493841068164\n",
      "\n",
      "Confusion Matrix 9 :\n",
      "                 Predict number 9   Predict not number 9\n",
      "Is number 9        1031                        4918\n",
      "Is not number 9    3896                       50155\n",
      "Sensitivity (Successfully predict number 9) : 0.17330643805681628\n",
      "Specificity (Successfully predict not number 9) : 0.9279199274759024\n",
      "\n",
      "error rate: 0.8199666666666667\n"
     ]
    }
   ],
   "source": [
    "totalTP = 0\n",
    "for label in range(10):\n",
    "    TP, FN, FP, TN = 0, 0, 0, 0\n",
    "    for n in range(60000):\n",
    "        if train_label_data[n] == label and w[n][label] >= 0.01:\n",
    "            TP += 1\n",
    "            totalTP += 1\n",
    "        elif train_label_data[n] == label and w[n][label] < 0.01:\n",
    "            FN += 1\n",
    "        elif train_label_data[n] != label and w[n][label] >= 0.01:\n",
    "            FP += 1\n",
    "        elif train_label_data[n] != label and w[n][label] < 0.01:\n",
    "            TN += 1\n",
    "    print(f'Confusion Matrix {label} :')\n",
    "    print(f'                 Predict number {label}   Predict not number {label}')\n",
    "    print(f'Is number {label}        {TP}                        {FN}')\n",
    "    print(f'Is not number {label}    {FP}                       {TN}')\n",
    "    print(f'Sensitivity (Successfully predict number {label}) : {TP/(TP + FN)}')\n",
    "    print(f'Specificity (Successfully predict not number {label}) : {TN/(TN + FP)}\\n')\n",
    "print(f'error rate: {1-totalTP/60000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.737856059607368e-35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
